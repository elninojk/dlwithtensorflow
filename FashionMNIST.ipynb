{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST.ipynb",
      "provenance": [],
      "mount_file_id": "1d4__xvhJPqLeJcmwlYS-p9hT8XSG5cKr",
      "authorship_tag": "ABX9TyMZEW3y05wy3RMOyRhBVFsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elninojk/dlwithtensorflow/blob/master/FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4k7FV8blzpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3uZuKM5MyvQ",
        "colab_type": "text"
      },
      "source": [
        "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "Some notes:\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger 2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling\n",
        "training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "I've started the code for you below -- how would you finish it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Crc54tNJfB",
        "colab_type": "code",
        "outputId": "a1e20cb1-fcae-4691-93fe-0edabd24227d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from os import path,getcwd,chdir\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVbhBhG6ZhqM",
        "colab_type": "code",
        "outputId": "87bf049f-20a0-4d48-ea1d-8c634798f086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "def train_mnist():\n",
        "\n",
        "  # I always thought about this , even i had min idea about ML.\n",
        "  # Why can't we stop if we achieve required acc, and here is the ANS\n",
        "  class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch, logs={}):\n",
        "        if(logs.get('accuracy')is None):\n",
        "          print(\"\\n NO\")\n",
        "        elif(logs.get('accuracy')>0.99):\n",
        "          print(\"\\n Reached 99% accuracy cancelling the training\")\n",
        "          self.model.stop_training = True\n",
        "  # data might be erased when notebook is powered off, so mounting gdrive and loading from there\n",
        "  (x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data(\n",
        "    path='/content/drive/My Drive/Colab Notebooks/mnist.npz')\n",
        "  # print(x_train.shape)\n",
        "\n",
        "  # normalization is must, i saw significant reduc in acc without norm\n",
        "  x_train = x_train / 255.0\n",
        "  x_test = x_test / 255.0,\n",
        "\n",
        "  #define model\n",
        "  callbacks = myCallback()\n",
        "  model = tf.keras.models.Sequential(\n",
        "      [\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(512, activation= tf.nn.relu),\n",
        "       tf.keras.layers.Dense(10,activation= tf.nn.softmax),\n",
        "      ]\n",
        "  )\n",
        "  #compile the model\n",
        "  model.compile(optimizer ='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  #fit the data\n",
        "  history = model.fit(x_train, y_train, epochs =10, callbacks= [callbacks])\n",
        "\n",
        "  #get the data\n",
        "  return history.epoch, history.history['accuracy']\n",
        "train_mnist()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2005 - accuracy: 0.9407\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0806 - accuracy: 0.9757\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0505 - accuracy: 0.9847\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0360 - accuracy: 0.9883\n",
            "Epoch 5/10\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9915\n",
            " Reached 99% accuracy cancelling the training\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0259 - accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4],\n",
              " [0.9407333135604858,\n",
              "  0.9757166504859924,\n",
              "  0.9847333431243896,\n",
              "  0.9882500171661377,\n",
              "  0.991516649723053])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}